{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada86d4b",
   "metadata": {},
   "source": [
    "# Solution 1: Linear Regression\n",
    "\n",
    "Complete implementation of linear regression using three different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b716f19",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the IID regression data\n",
    "data_path = Path(\"../Data/Homework-1/regression_data_iid.npz\")\n",
    "data = np.load(data_path)\n",
    "\n",
    "x = data['x']\n",
    "y = data['y'] \n",
    "y_true = data['y_true']\n",
    "\n",
    "print(f\"Data loaded: {len(x)} points\")\n",
    "print(f\"X range: [{x.min():.2f}, {x.max():.2f}]\")\n",
    "print(f\"Y range: [{y.min():.2f}, {y.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b4296",
   "metadata": {},
   "source": [
    "Let's visualize the data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b2419",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, alpha=0.6, color='blue', s=20, label='Noisy data')\n",
    "plt.plot(x, y_true, 'r-', linewidth=2, label='True function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('IID Regression Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7dab85",
   "metadata": {},
   "source": [
    "## Problem 1.1: Explicit Linear Regression Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf2edb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def explicit_linear_regression(x, y):\n",
    "    \"\"\"\n",
    "    Solve linear regression using the explicit normal equation.\n",
    "    \n",
    "    Args:\n",
    "        x: Input features (n_samples,)\n",
    "        y: Target values (n_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        beta: Parameters [intercept, slope]\n",
    "    \"\"\"\n",
    "    # TODO FILL THIS IN\n",
    "    pass\n",
    "    \n",
    "# Fit the model\n",
    "beta_explicit = explicit_linear_regression(x, y)\n",
    "print(f\"Explicit solution: intercept = {beta_explicit[0]:.4f}, slope = {beta_explicit[1]:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_explicit = beta_explicit[0] + beta_explicit[1] * x\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, alpha=0.6, color='blue', s=20, label='Noisy data')\n",
    "plt.plot(x, y_pred_explicit, 'r-', linewidth=2, label='Predictions')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Explicit Linear Regression Predictions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be616f5f",
   "metadata": {},
   "source": [
    "## Problem 1.2: Gradient Descent Implementation\n",
    "This problem practices using gradient descent to solve minimization problems. In practice, this might not be how you actually do linear regression, but it's warmup for other problems in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d623d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def gradient_descent_linear_regression(x, y, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Solve linear regression using gradient descent.\n",
    "    \n",
    "    Args:\n",
    "        x: Input features (n_samples,)\n",
    "        y: Target values (n_samples,)\n",
    "        learning_rate: Step size for gradient descent\n",
    "        max_iterations: Maximum number of iterations\n",
    "        tolerance: Convergence tolerance\n",
    "    \n",
    "    Returns:\n",
    "        beta: Parameters [intercept, slope]\n",
    "        costs: Cost function values over iterations\n",
    "    \"\"\"\n",
    "    # TODO FILL THIS IN\n",
    "    pass\n",
    "    \n",
    "    return beta, costs\n",
    "\n",
    "def predictor(beta_values, x):\n",
    "    \"\"\"\n",
    "    Make predictions using linear regression parameters.\n",
    "    \n",
    "    Args:\n",
    "        beta_values: Array of regression parameters [intercept, slope]\n",
    "        x: Input features (n_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        y_pred: Predicted values (n_samples,)\n",
    "    \"\"\"\n",
    "    return beta_values[0] + beta_values[1] * x\n",
    "\n",
    "# Fit the model\n",
    "beta_gd, costs = gradient_descent_linear_regression(x, y, learning_rate=0.1, max_iterations=1000)\n",
    "print(f\"Gradient descent solution: intercept = {beta_gd[0]:.4f}, slope = {beta_gd[1]:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gd = predictor(beta_gd, x)\n",
    "\n",
    "# Plot convergence\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(costs)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Gradient Descent Convergence')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, alpha=0.6, color='blue', s=20, label='Noisy data')\n",
    "plt.plot(x, y_pred_gd, 'r-', linewidth=2, label='Predictions')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Linear Regression Predictions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d29568",
   "metadata": {},
   "source": [
    "### Problem 1.2 Bonus\n",
    "Can you make the gradient descent solution run faster (in wall-clock time) than the explicit solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877d527",
   "metadata": {},
   "source": [
    "## Problem 1.3: Scipy Optimization\n",
    "For this problem, I want you to be aware of existing tools for doing linear regression. Take a look at the scipy documentation to find how to use its linear regression functions. In particular, take a look at the minimize function from scipy.optimize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7463c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipy_linear_regression(x, y):\n",
    "    \"\"\"\n",
    "    Solve linear regression using scipy optimization.\n",
    "    \n",
    "    Args:\n",
    "        x: Input features (n_samples,)\n",
    "        y: Target values (n_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        beta: Parameters [intercept, slope]\n",
    "    \"\"\"\n",
    "    # TODO FILL THIS IN\n",
    "    pass \n",
    "    \n",
    "# Fit the model\n",
    "beta_scipy = scipy_linear_regression(x, y)\n",
    "print(f\"Scipy solution: intercept = {beta_scipy[0]:.4f}, slope = {beta_scipy[1]:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_scipy = beta_scipy[0] + beta_scipy[1] * x\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, alpha=0.6, color='blue', s=20, label='Noisy data')\n",
    "plt.plot(x, y_pred_scipy, 'r-', linewidth=2, label='Predictions')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Explicit Linear Regression Predictions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad4fef",
   "metadata": {},
   "source": [
    "## Problem 1.4: Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913456ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare solutions\n",
    "print(\"=== Solution Comparison ===\")\n",
    "print(f\"Explicit:         intercept = {beta_explicit[0]:.6f}, slope = {beta_explicit[1]:.6f}\")\n",
    "print(f\"Gradient Descent: intercept = {beta_gd[0]:.6f}, slope = {beta_gd[1]:.6f}\")\n",
    "print(f\"Scipy:            intercept = {beta_scipy[0]:.6f}, slope = {beta_scipy[1]:.6f}\")\n",
    "\n",
    "# Compute MSE for each method\n",
    "mse_explicit = np.mean((y_pred_explicit - y)**2)\n",
    "mse_gd = np.mean((y_pred_gd - y)**2)\n",
    "mse_scipy = np.mean((y_pred_scipy - y)**2)\n",
    "\n",
    "print(\"\\n=== Mean Squared Error ===\")\n",
    "print(f\"Explicit:         MSE = {mse_explicit:.6f}\")\n",
    "print(f\"Gradient Descent: MSE = {mse_gd:.6f}\")\n",
    "print(f\"Scipy:            MSE = {mse_scipy:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d58fd56",
   "metadata": {},
   "source": [
    "### Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3abed",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(x, y, alpha=0.6, color='lightblue', s=20, label='Noisy data')\n",
    "plt.plot(x, y_true, 'k--', linewidth=2, label='True function')\n",
    "\n",
    "# Sort x for smooth lines\n",
    "sort_idx = np.argsort(x)\n",
    "x_sorted = x[sort_idx]\n",
    "\n",
    "plt.plot(x_sorted, (beta_explicit[0] + beta_explicit[1] * x_sorted), 'r-', \n",
    "         linewidth=2, label=f'Explicit (MSE: {mse_explicit:.4f})')\n",
    "plt.plot(x_sorted, (beta_gd[0] + beta_gd[1] * x_sorted), 'g-', \n",
    "         linewidth=2, label=f'Gradient Descent (MSE: {mse_gd:.4f})')\n",
    "plt.plot(x_sorted, (beta_scipy[0] + beta_scipy[1] * x_sorted), 'b-', \n",
    "         linewidth=2, label=f'Scipy (MSE: {mse_scipy:.4f})')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Comparison of Linear Regression Methods')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211bbf99",
   "metadata": {},
   "source": [
    "## What should we learn from this and expect to see?\n",
    "\n",
    "1. **Accuracy**: All three methods should give essentially identical results (within numerical precision) \n",
    "   since they're all solving the same optimization problem. The explicit solution is mathematically exact,\n",
    "   while gradient descent and scipy are iterative approximations that converge to the same solution.\n",
    "\n",
    "2. **Computational Efficiency**: \n",
    "   - **Explicit**: Fastest for small problems, involves matrix operations\n",
    "   - **Gradient Descent**: Slowest, often requires many iterations\n",
    "   - **Scipy**: Fast, uses optimizations to avoid taking matrix inverses. \n",
    "\n",
    "3. **Convergence**: Gradient descent should converge in ~50-200 iterations depending on learning rate.\n",
    "\n",
    "4. **Parameter Differences**: Minimal differences due to numerical precision. Gradient descent might \n",
    "   have slightly different results due to random initialization and early stopping.\n",
    "\n",
    "5. **When to Use Each Method**:\n",
    "   - **Explicit**: Small datasets, when you need exact solution, mostly used for educational purposes.\n",
    "   - **Gradient Descent**: Primarily used here for educational purposes.\n",
    "   - **Scipy**: Production code, complex cost functions, when you need robust optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea59cf",
   "metadata": {},
   "source": [
    "## Problem 1.5 Extension to Polynomial Features\n",
    "If you visualized the data above, you might note that it's not actually linear. As discussed in class, you can construct your own features within which the problem looks linear. Here, we'll construct some polynomial features and use those for lienar regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c540dca9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def polynomial_regression(x, y, degree=2):\n",
    "    \"\"\"\n",
    "    Solve polynomial regression using explicit solution. Use a 2d polynomial. \n",
    "    \n",
    "    Args:\n",
    "        x: Input features (n_samples,)\n",
    "        y: Target values (n_samples,)\n",
    "        degree: Degree of polynomial\n",
    "    \n",
    "    Returns:\n",
    "        beta: Parameters [intercept, x^1 coeff, x^2 coeff, ...]\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "    # TODO FILL THIS IN\n",
    "    return beta\n",
    "\n",
    "# Fit quadratic model (matches our true function better)\n",
    "beta_poly = polynomial_regression(x, y, degree=2)\n",
    "print(f\"Polynomial solution: intercept = {beta_poly[0]:.4f}, x = {beta_poly[1]:.4f}, x^2 = {beta_poly[2]:.4f}\")\n",
    "\n",
    "# Compare with true function coefficients: f(x) = 1.0 + 2.5*x + 0.3*x^2\n",
    "print(f\"True function:       intercept = 1.0000, x = 2.5000, x^2 = 0.3000\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_poly = beta_poly[0] + beta_poly[1] * x + beta_poly[2] * x**2\n",
    "mse_poly = np.mean((y_pred_poly - y)**2)\n",
    "\n",
    "print(f\"Polynomial MSE: {mse_poly:.6f} (should be lower than linear!)\")\n",
    "\n",
    "# Visualize polynomial fit\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, alpha=0.6, color='lightblue', s=20, label='Noisy data')\n",
    "plt.plot(x_sorted, y_true[sort_idx], 'k--', linewidth=2, label='True function')\n",
    "plt.plot(x_sorted, (beta_explicit[0] + beta_explicit[1] * x_sorted), 'r-', \n",
    "         linewidth=2, label=f'Linear (MSE: {mse_explicit:.4f})')\n",
    "\n",
    "y_pred_poly_sorted = beta_poly[0] + beta_poly[1] * x_sorted + beta_poly[2] * x_sorted**2\n",
    "plt.plot(x_sorted, y_pred_poly_sorted, 'purple', \n",
    "         linewidth=2, label=f'Quadratic (MSE: {mse_poly:.4f})')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Linear vs Polynomial Regression')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f9c323",
   "metadata": {},
   "source": [
    "# Problem 2: Non-linear Data and Cross-Validation\n",
    "In the previous problem, we focused on a dataset that was pretty explicitly close to linear. Because we were always fitting it with a linear function and the fitting process had no hyperparameters, there was no possibility of overfitting. Now, we explore a setting where we have some control over the function that we're fitting and so there's the possibility of overfitting. We explore fitting with polynomials of different degree and see how cross-k validation can be used to help us avoid some amount of overfitting. We'll get some practice implementing it ourselves and then make sure we also know how to do it in scikit-learn. \n",
    "\n",
    "Now let's work with a more complex, non-linear dataset and explore:\n",
    "- Train-test splits and model complexity\n",
    "- K-fold cross-validation (both manual and scikit-learn implementations)\n",
    "- Overfitting detection and prevention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab0040",
   "metadata": {},
   "source": [
    "## Generate Non-linear Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09081b06",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_nonlinear_data(n_samples=100, noise_std=0.3, seed=42):\n",
    "    \"\"\"\n",
    "    Generate a complex non-linear dataset for testing polynomial regression.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of data points to generate\n",
    "        noise_std: Standard deviation of Gaussian noise to add\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        x: Input features (n_samples,)\n",
    "        y: Noisy target values (n_samples,)\n",
    "        y_true: True function values without noise (n_samples,)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate input points\n",
    "    x = np.linspace(-2, 2, n_samples)\n",
    "    \n",
    "    # Complex non-linear function\n",
    "    y_true = 0.5 * x**3 - 2 * x**2 + x + 1 + 0.5 * np.sin(5 * x)\n",
    "    \n",
    "    # Add noise\n",
    "    y = y_true + np.random.normal(0, noise_std, n_samples)\n",
    "    \n",
    "    return x, y, y_true\n",
    "\n",
    "# Generate the dataset\n",
    "x_nl, y_nl, y_true_nl = generate_nonlinear_data(n_samples=80, noise_std=0.4)\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_nl, y_nl, alpha=0.7, color='blue', s=30, label='Noisy data')\n",
    "plt.plot(x_nl, y_true_nl, 'r-', linewidth=2, label='True function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Non-linear Dataset')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0684a95e",
   "metadata": {},
   "source": [
    "# Problem 2A: Manual Implementation (No Scikit-Learn)\n",
    "\n",
    "First, let's implement polynomial regression and cross-validation from scratch to understand the concepts. Take your data, split it into 70% train and 30% test and then perform 5-fold cross-validation to create estimates of the std. deviation of the error for each of the polynomial degrees. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb8126",
   "metadata": {},
   "source": [
    "## Manual Train-Test Split and Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e71e16",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def manual_train_test_split(X, y, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Manually implement train-test split without using sklearn.\n",
    "    \n",
    "    Args:\n",
    "        X: Input features (n_samples, n_features)\n",
    "        y: Target values (n_samples,)\n",
    "        test_size: Fraction of data to use for testing (0.0 to 1.0)\n",
    "        random_state: Random seed for reproducible splits\n",
    "    \n",
    "    Returns:\n",
    "        X_train: Training features\n",
    "        X_test: Test features  \n",
    "        y_train: Training labels\n",
    "        y_test: Test labels\n",
    "    \"\"\"\n",
    "    # TODO FILL THIS IN\n",
    "    pass\n",
    "\n",
    "def create_polynomial_features(x, degree):\n",
    "    \"\"\"\n",
    "    Create polynomial features manually (without sklearn).\n",
    "    \n",
    "    Args:\n",
    "        x: Input features (n_samples, 1) or (n_samples,)\n",
    "        degree: Maximum degree of polynomial features\n",
    "    \n",
    "    Returns:\n",
    "        X: Design matrix with polynomial features (n_samples, degree+1)\n",
    "           Columns are [1, x, x^2, x^3, ..., x^degree]\n",
    "    \"\"\"\n",
    "    # TODO FILL THIS IN\n",
    "    pass\n",
    "\n",
    "def fit_polynomial_manual(X, y):\n",
    "    \"\"\"\n",
    "    Fit polynomial regression using the normal equation.\n",
    "    \n",
    "    Args:\n",
    "        X: Design matrix with polynomial features (n_samples, n_features)\n",
    "        y: Target values (n_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        beta: Polynomial coefficients (n_features,)\n",
    "    \"\"\"\n",
    "    # Add small regularization for numerical stability\n",
    "    # TODO FILL THIS IN\n",
    "    pass\n",
    "\n",
    "def predict_polynomial_manual(X, beta):\n",
    "    \"\"\"\n",
    "    Make predictions using fitted polynomial coefficients.\n",
    "    \n",
    "    Args:\n",
    "        X: Design matrix with polynomial features (n_samples, n_features)\n",
    "        beta: Polynomial coefficients (n_features,)\n",
    "    \n",
    "    Returns:\n",
    "        y_pred: Predicted values (n_samples,)\n",
    "    \"\"\"\n",
    "    # TODO FILL THIS IN\n",
    "    pass\n",
    "\n",
    "def mean_squared_error_manual(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Mean Squared Error manually (without sklearn).\n",
    "    \n",
    "    Args:\n",
    "        y_true: True target values (n_samples,)\n",
    "        y_pred: Predicted values (n_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        mse: Mean squared error (scalar)\n",
    "    \"\"\"\n",
    "    # TODO FILL THIS IN\n",
    "    pass\n",
    "\n",
    "# Manual train-test split\n",
    "x_nl_reshaped = x_nl.reshape(-1, 1)\n",
    "X_train_manual, X_test_manual, y_train_manual, y_test_manual = manual_train_test_split(\n",
    "    x_nl_reshaped, y_nl, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Test different polynomial degrees manually\n",
    "degrees = range(1, 16)\n",
    "train_errors_manual = []\n",
    "test_errors_manual = []\n",
    "\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    X_train_poly = create_polynomial_features(X_train_manual, degree)\n",
    "    X_test_poly = create_polynomial_features(X_test_manual, degree)\n",
    "    \n",
    "    # Fit model\n",
    "    beta = fit_polynomial_manual(X_train_poly, y_train_manual)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = predict_polynomial_manual(X_train_poly, beta)\n",
    "    y_test_pred = predict_polynomial_manual(X_test_poly, beta)\n",
    "    \n",
    "    # Calculate errors\n",
    "    train_mse = mean_squared_error_manual(y_train_manual, y_train_pred)\n",
    "    test_mse = mean_squared_error_manual(y_test_manual, y_test_pred)\n",
    "    \n",
    "    train_errors_manual.append(train_mse)\n",
    "    test_errors_manual.append(test_mse)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(degrees, train_errors_manual, 'o-', label='Training Error', color='blue')\n",
    "plt.plot(degrees, test_errors_manual, 'o-', label='Test Error', color='red')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Manual Implementation: Training vs Test Error')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "optimal_degree_manual = degrees[np.argmin(test_errors_manual)]\n",
    "print(f\"Manual implementation - Optimal degree: {optimal_degree_manual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5036d119",
   "metadata": {},
   "source": [
    "## Manual K-Fold Cross-Validation\n",
    "In K-fold cross validation we construct $k$ train test splits. We then train a model for each of these splits and compute the standard deviation of our fits around to the splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5992b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_kfold_split(n_samples, k=5, shuffle=True, random_state=42):\n",
    "    \"\"\"\n",
    "    Manually implement k-fold cross-validation splits.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Total number of samples in dataset\n",
    "        k: Number of folds for cross-validation\n",
    "        shuffle: Whether to shuffle data before splitting\n",
    "        random_state: Random seed for reproducible splits\n",
    "    \n",
    "    Returns:\n",
    "        folds: List of (train_indices, test_indices) tuples for each fold\n",
    "    \"\"\"\n",
    "    # TODO FILL THIS IN\n",
    "    pass\n",
    "\n",
    "def manual_cross_validate(X, y, degree, k=5):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation manually for polynomial regression.\n",
    "    \n",
    "    Args:\n",
    "        X: Input features (n_samples, n_input_features)\n",
    "        y: Target values (n_samples,)\n",
    "        degree: Polynomial degree to test\n",
    "        k: Number of folds for cross-validation\n",
    "    \n",
    "    Returns:\n",
    "        fold_errors: Array of MSE values for each fold (k,)\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    folds = manual_kfold_split(n_samples, k=k, random_state=42)\n",
    "\n",
    "    # TODO fill the rest of this in. Basically, you will need to do the fits\n",
    "    # for each fold and track the final MSE of each fit. \n",
    "    pass\n",
    "\n",
    "# Manual cross-validation\n",
    "cv_scores_manual = []\n",
    "cv_stds_manual = []\n",
    "\n",
    "print(\"Performing manual 5-fold cross-validation...\")\n",
    "for degree in degrees:\n",
    "    fold_errors = manual_cross_validate(x_nl_reshaped, y_nl, degree, k=5)\n",
    "    \n",
    "    # Filter out infinite values\n",
    "    valid_errors = fold_errors[np.isfinite(fold_errors)]\n",
    "    if len(valid_errors) > 0:\n",
    "        cv_scores_manual.append(valid_errors.mean())\n",
    "        cv_stds_manual.append(valid_errors.std())\n",
    "    else:\n",
    "        cv_scores_manual.append(np.inf)\n",
    "        cv_stds_manual.append(0)\n",
    "\n",
    "# Plot manual cross-validation results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.errorbar(degrees, cv_scores_manual, yerr=cv_stds_manual, \n",
    "             marker='o', capsize=5, capthick=2, label='Manual 5-Fold CV')\n",
    "plt.plot(degrees, test_errors_manual, 'r--', alpha=0.7, label='Manual Single Split')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Manual Implementation: Cross-Validation vs Single Split')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "optimal_degree_cv_manual = degrees[np.argmin(cv_scores_manual)]\n",
    "print(f\"Manual CV - Optimal degree: {optimal_degree_cv_manual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca08a4a",
   "metadata": {},
   "source": [
    "# Problem 2B: Scikit-Learn Implementation\n",
    "\n",
    "Now let's use scikit-learn to do the same analysis and compare results. You don't have to do anything here, I just wanted to give you some code for how you might implement it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a92b86",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Scikit-learn train-test split\n",
    "X_train_sk, X_test_sk, y_train_sk, y_test_sk = train_test_split(\n",
    "    x_nl_reshaped, y_nl, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Test different polynomial degrees with scikit-learn\n",
    "train_errors_sk = []\n",
    "test_errors_sk = []\n",
    "\n",
    "for degree in degrees:\n",
    "    # Create polynomial pipeline\n",
    "    poly_model = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=degree)),\n",
    "        ('linear', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    # Fit the model\n",
    "    poly_model.fit(X_train_sk, y_train_sk)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = poly_model.predict(X_train_sk)\n",
    "    y_test_pred = poly_model.predict(X_test_sk)\n",
    "    \n",
    "    # Calculate errors\n",
    "    train_mse = mean_squared_error(y_train_sk, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test_sk, y_test_pred)\n",
    "    \n",
    "    train_errors_sk.append(train_mse)\n",
    "    test_errors_sk.append(test_mse)\n",
    "\n",
    "optimal_degree_sk = degrees[np.argmin(test_errors_sk)]\n",
    "print(f\"Scikit-learn - Optimal degree: {optimal_degree_sk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d1291",
   "metadata": {},
   "source": [
    "## Scikit-Learn Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_sklearn_kfold(X, y, degrees, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate using scikit-learn k-fold cross-validation.\n",
    "    \n",
    "    Args:\n",
    "        X: Input features (n_samples, n_input_features)\n",
    "        y: Target values (n_samples,)\n",
    "        degrees: List of polynomial degrees to evaluate\n",
    "        k: Number of folds for cross-validation\n",
    "    \n",
    "    Returns:\n",
    "        cv_scores: List of mean cross-validation scores for each degree\n",
    "        cv_stds: List of standard deviations of cross-validation scores for each degree\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_scores = []\n",
    "    cv_stds = []\n",
    "    \n",
    "    for degree in degrees:\n",
    "        # Create polynomial pipeline\n",
    "        poly_model = Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=degree)),\n",
    "            ('linear', LinearRegression())\n",
    "        ])\n",
    "        \n",
    "        # Perform k-fold cross-validation\n",
    "        scores = cross_val_score(poly_model, X, y, cv=kf, \n",
    "                               scoring='neg_mean_squared_error')\n",
    "        \n",
    "        # Convert to positive MSE\n",
    "        mse_scores = -scores\n",
    "        \n",
    "        cv_scores.append(mse_scores.mean())\n",
    "        cv_stds.append(mse_scores.std())\n",
    "    \n",
    "    return cv_scores, cv_stds\n",
    "\n",
    "# Scikit-learn cross-validation\n",
    "cv_scores_sk, cv_stds_sk = evaluate_with_sklearn_kfold(x_nl_reshaped, y_nl, degrees, k=5)\n",
    "\n",
    "optimal_degree_cv_sk = degrees[np.argmin(cv_scores_sk)]\n",
    "print(f\"Scikit-learn CV - Optimal degree: {optimal_degree_cv_sk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b032e965",
   "metadata": {},
   "source": [
    "## Comparison: Manual vs Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef403a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all implementations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Train-Test Split Comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(degrees, train_errors_manual, 'o-', label='Manual Train', color='blue', alpha=0.7)\n",
    "plt.plot(degrees, test_errors_manual, 'o-', label='Manual Test', color='red', alpha=0.7)\n",
    "plt.plot(degrees, train_errors_sk, 's--', label='Sklearn Train', color='blue')\n",
    "plt.plot(degrees, test_errors_sk, 's--', label='Sklearn Test', color='red')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Train-Test Split: Manual vs Scikit-Learn')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Plot 2: Cross-Validation Comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.errorbar(degrees, cv_scores_manual, yerr=cv_stds_manual, \n",
    "             marker='o', capsize=3, alpha=0.7, label='Manual CV')\n",
    "plt.errorbar(degrees, cv_scores_sk, yerr=cv_stds_sk, \n",
    "             marker='s', capsize=3, label='Sklearn CV')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Cross-Validation: Manual vs Scikit-Learn')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Plot 3: Model Visualization (using optimal degree)\n",
    "plt.subplot(2, 2, 3)\n",
    "x_plot = np.linspace(-2, 2, 200)\n",
    "X_plot = x_plot.reshape(-1, 1)\n",
    "\n",
    "# Manual implementation\n",
    "X_plot_poly_manual = create_polynomial_features(X_plot, optimal_degree_cv_manual)\n",
    "X_train_poly_manual = create_polynomial_features(X_train_manual, optimal_degree_cv_manual)\n",
    "beta_manual = fit_polynomial_manual(X_train_poly_manual, y_train_manual)\n",
    "y_plot_manual = predict_polynomial_manual(X_plot_poly_manual, beta_manual)\n",
    "\n",
    "plt.scatter(x_nl, y_nl, alpha=0.6, color='lightblue', s=20, label='Data')\n",
    "plt.plot(x_plot, y_plot_manual, 'b-', linewidth=2, label=f'Manual (deg {optimal_degree_cv_manual})')\n",
    "plt.plot(x_nl, y_true_nl, 'k--', alpha=0.7, label='True function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Manual Implementation Result')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Scikit-learn visualization\n",
    "plt.subplot(2, 2, 4)\n",
    "poly_model_sk = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=optimal_degree_cv_sk)),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "poly_model_sk.fit(X_train_sk, y_train_sk)\n",
    "y_plot_sk = poly_model_sk.predict(X_plot)\n",
    "\n",
    "plt.scatter(x_nl, y_nl, alpha=0.6, color='lightblue', s=20, label='Data')\n",
    "plt.plot(x_plot, y_plot_sk, 'g-', linewidth=2, label=f'Sklearn (deg {optimal_degree_cv_sk})')\n",
    "plt.plot(x_nl, y_true_nl, 'k--', alpha=0.7, label='True function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Scikit-Learn Implementation Result')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab878c98",
   "metadata": {},
   "source": [
    "## Analysis Summary\n",
    "\n",
    "**Key Things you might learn / expect:**\n",
    "\n",
    "1. **Implementation Consistency**: Manual and scikit-learn implementations should give very similar results,\n",
    "   validating our understanding of the underlying algorithms.\n",
    "\n",
    "2. **Cross-Validation**: Cross-validation should indicate that there's some noise in which value of beta looks the best. If we didn't cross-validate, we might not see it. \n",
    "\n",
    "3. **Overfitting Detection**: Both approaches clearly show overfitting around degree 8-10, where\n",
    "   training error continues decreasing but test/validation error increases.\n",
    "\n",
    "\n",
    "Question: which polynomial degree looks best? Why?\n",
    "\n",
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa335cfd",
   "metadata": {},
   "source": [
    "# Problem 3: Sentiment Analysis - Bag of Words vs OpenAI Embeddings\n",
    "\n",
    "In this final problem, we'll explore text classification using two very different approaches:\n",
    "1. **Bag of Words (BoW)**: Traditional sparse feature representation\n",
    "2. **OpenAI Embeddings**: Modern dense vector representations\n",
    "\n",
    "We'll use the [multiclass sentiment analysis dataset](https://huggingface.co/datasets/Sp1786/multiclass-sentiment-analysis-dataset) \n",
    "which contains ~41k text samples with 3 sentiment classes: negative, neutral, positive.\n",
    "\n",
    "## Learning Objectives\n",
    "- Practice with traditional NLP feature engineering (bag of words)\n",
    "- Learn to use modern embedding APIs (OpenAI)\n",
    "- Apply linear models to text classification\n",
    "- Understand how to do multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3991723",
   "metadata": {},
   "source": [
    "## Load Sentiment Analysis Dataset\n",
    "\n",
    "**Note**: This will download the dataset from Hugging Face (~4.7MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "def load_sentiment_data(subset_size=1000):\n",
    "    \"\"\"\n",
    "    Load and prepare the sentiment analysis dataset.\n",
    "    \n",
    "    Args:\n",
    "        subset_size: Number of samples to use (for computational efficiency)\n",
    "    \n",
    "    Returns:\n",
    "        train_texts, test_texts, train_labels, test_labels\n",
    "    \"\"\"\n",
    "    print(\"Loading sentiment analysis dataset from Hugging Face...\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(\"Sp1786/multiclass-sentiment-analysis-dataset\")\n",
    "    \n",
    "    # Convert to pandas for easier manipulation\n",
    "    train_df = pd.DataFrame(dataset['train'])\n",
    "    test_df = pd.DataFrame(dataset['test'])\n",
    "    \n",
    "    print(f\"Full dataset size: Train={len(train_df)}, Test={len(test_df)}\")\n",
    "    print(f\"Classes: {train_df['sentiment'].unique()}\")\n",
    "    print(f\"Class distribution:\\n{train_df['sentiment'].value_counts()}\")\n",
    "    \n",
    "    # Take a balanced subset for efficiency\n",
    "    if subset_size < len(train_df):\n",
    "        samples_per_class = subset_size // 3\n",
    "        train_subset = []\n",
    "        \n",
    "        for sentiment in ['negative', 'neutral', 'positive']:\n",
    "            class_data = train_df[train_df['sentiment'] == sentiment].sample(\n",
    "                n=samples_per_class, random_state=42\n",
    "            )\n",
    "            train_subset.append(class_data)\n",
    "        \n",
    "        train_df = pd.concat(train_subset).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Also subset test data\n",
    "    test_subset_size = min(300, len(test_df))\n",
    "    test_df = test_df.sample(n=test_subset_size, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Using subset: Train={len(train_df)}, Test={len(test_df)}\")\n",
    "    \n",
    "    # Extract texts and labels\n",
    "    train_texts = train_df['text'].tolist()\n",
    "    test_texts = test_df['text'].tolist()\n",
    "    \n",
    "    # Convert sentiment labels to integers\n",
    "    label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "    train_labels = train_df['sentiment'].map(label_map).values\n",
    "    test_labels = test_df['sentiment'].map(label_map).values\n",
    "    \n",
    "    return train_texts, test_texts, train_labels, test_labels\n",
    "\n",
    "# Load the data\n",
    "train_texts, test_texts, train_labels, test_labels = load_sentiment_data(subset_size=900)\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\n=== Sample Texts ===\")\n",
    "for i in range(3):\n",
    "    sentiment_names = ['negative', 'neutral', 'positive']\n",
    "    print(f\"{sentiment_names[train_labels[i]]}: {train_texts[i][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e163b6",
   "metadata": {},
   "source": [
    "## Problem 3A: Bag of Words Approach\n",
    "\n",
    "In this section, you'll implement text classification using the traditional \"bag of words\" approach.\n",
    "This creates sparse feature vectors based on word counts in the text.\n",
    "\n",
    "**Your task**: Complete the `bag_of_words_classification` function below by:\n",
    "1. Constructing a BOW feature representation (you can use sci-kit learn here if you want or implement it yourself)\n",
    "2. Train the model and return results in the defined format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d51d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def bag_of_words_classification(train_texts, test_texts, train_labels, test_labels):\n",
    "    \"\"\"\n",
    "    Implement sentiment classification using bag of words.\n",
    "    \n",
    "    Args:\n",
    "        train_texts: List of training text samples\n",
    "        test_texts: List of test text samples\n",
    "        train_labels: Array of training labels (n_train_samples,)\n",
    "        test_labels: Array of test labels (n_test_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing results for the count method with\n",
    "              train_acc, test_acc, and predictions\n",
    "    \"\"\"\n",
    "    print(\"=== Bag of Words Approach ===\")\n",
    "    \n",
    "    # TODO fill in the fitting\n",
    "    \n",
    "    # TODO: You need to return a dictionary with the results\n",
    "    # The format should be:\n",
    "    # return {\n",
    "    #     'count': {'train_acc': train_acc_count, 'test_acc': test_acc_count, 'predictions': test_pred_count}\n",
    "    # }\n",
    "    pass\n",
    "\n",
    "# Run bag of words experiments\n",
    "bow_results = bag_of_words_classification(train_texts, test_texts, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a86f27",
   "metadata": {},
   "source": [
    "## Problem 3B: OpenAI Embeddings Approach\n",
    "\n",
    "Modern approach using dense vector representations from OpenAI's embedding models. \n",
    "These are pre-trained models that convert text into high-dimensional vectors that capture semantic meaning.\n",
    "\n",
    "**Your tasks**:\n",
    "1. Set up your OpenAI API key (see instructions below)\n",
    "2. Complete the `get_openai_embeddings` function to handle API calls\n",
    "3. Complete the `openai_embeddings_classification` function\n",
    "4. Compare results with the bag-of-words approach\n",
    "\n",
    "### API Key Setup\n",
    "**Note**: You'll need an OpenAI API key. Create one at https://platform.openai.com\n",
    "\n",
    "**IMPORTANT SECURITY**: Never put API keys directly in your code! \n",
    "\n",
    "**Recommended approach**: Use a `.env` file\n",
    "1. Create a `.env` file in your project root (already in .gitignore)\n",
    "2. Add: `OPENAI_API_KEY=your-api-key-here`\n",
    "3. The code below will automatically load it\n",
    "\n",
    "**WARNING**: Your API key should NEVER be in your commit history or public repos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20848d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f52f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your API key method (uncomment ONE of the following):\n",
    "\n",
    "# Option 1: Load from .env file (Recommended)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# IT WILL PRINT TRUE IF THIS SUCCEEDED\n",
    "\n",
    "# Option 2: Interactive input (most secure for shared environments). \n",
    "# I am not making it the default because it's more annoying but it can be the more secure one. \n",
    "# the sense in which it is the less secure one is it can induce you to write down your private key\n",
    "# and store it somewhere where people can easily access it. \n",
    "\n",
    "# import getpass\n",
    "# os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Enter OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e478c42",
   "metadata": {},
   "source": [
    "### Step 1: Implement OpenAI Embeddings Function\n",
    "\n",
    "The function below handles API calls to OpenAI. It's implemented for you but all you need to know is that it takes the total text and converts it into a feature vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480de58d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_openai_embeddings(texts, model=\"text-embedding-3-small\", batch_size=100):\n",
    "    \"\"\"\n",
    "    Get OpenAI embeddings for a list of texts.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of text strings\n",
    "        model: OpenAI embedding model to use\n",
    "        batch_size: Number of texts to process at once\n",
    "    \n",
    "    Returns:\n",
    "        embeddings: numpy array of shape (n_texts, embedding_dim)\n",
    "    \"\"\"\n",
    "    # Get API key from environment\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"WARNING: No OpenAI API key found!\")\n",
    "        print(\"Please create a .env file with OPENAI_API_KEY=your-key\")\n",
    "        print(\"For this demo, we'll use random embeddings instead\")\n",
    "        \n",
    "        # Return random embeddings for demo purposes\n",
    "        np.random.seed(42)\n",
    "        return np.random.randn(len(texts), 1536)  # text-embedding-3-small dimension\n",
    "    \n",
    "    print(\"API key loaded successfully\")\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    print(f\"Getting OpenAI embeddings for {len(texts)} texts...\")\n",
    "    print(f\"Model: {model}\")\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    # Process in batches to avoid rate limits\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        try:\n",
    "            # Get embeddings for this batch\n",
    "            response = client.embeddings.create(\n",
    "                input=batch_texts,\n",
    "                model=model\n",
    "            )\n",
    "            \n",
    "            # Extract embeddings\n",
    "            batch_embeddings = [item.embedding for item in response.data]\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "            \n",
    "            print(f\"Processed batch {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1}\")\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {i//batch_size + 1}: {e}\")\n",
    "            print(\"Using random embeddings for this batch\")\n",
    "            # Fallback to random embeddings\n",
    "            batch_size_actual = len(batch_texts)\n",
    "            random_embeddings = np.random.randn(batch_size_actual, 1536).tolist()\n",
    "            all_embeddings.extend(random_embeddings)\n",
    "    \n",
    "    return np.array(all_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9e695",
   "metadata": {},
   "source": [
    "### Step 2: Implement Classification with OpenAI Embeddings\n",
    "\n",
    "**Your task**: Complete this function by:\n",
    "1. Understanding how embeddings are obtained (already implemented)\n",
    "2. Adding print statements to examine embedding properties\n",
    "3. Training a logistic regression classifier on the embeddings\n",
    "4. Returning results in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f93f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_embeddings_classification(train_texts, test_texts, train_labels, test_labels):\n",
    "    \"\"\"\n",
    "    Implement sentiment classification using OpenAI embeddings.\n",
    "    \n",
    "    Args:\n",
    "        train_texts: List of training text samples\n",
    "        test_texts: List of test text samples\n",
    "        train_labels: Array of training labels (n_train_samples,)\n",
    "        test_labels: Array of test labels (n_test_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing train_acc, test_acc, predictions, \n",
    "              embeddings_train, and embeddings_test\n",
    "    \"\"\"\n",
    "    print(\"=== OpenAI Embeddings Approach ===\")\n",
    "    \n",
    "    # Get embeddings (this may take a few minutes and cost ~$0.01-0.05)\n",
    "    print(\"Getting training embeddings...\")\n",
    "    X_train_embeddings = get_openai_embeddings(train_texts)\n",
    "    \n",
    "    print(\"Getting test embeddings...\")\n",
    "    X_test_embeddings = get_openai_embeddings(test_texts)\n",
    "    \n",
    "    # TODO: Add print statements to examine embedding properties\n",
    "    # You should print:\n",
    "    # - Embedding dimensionality: X_train_embeddings.shape[1] \n",
    "    # - Embedding range: [X_train_embeddings.min():.3f}, {X_train_embeddings.max():.3f}]\n",
    "    \n",
    "    # TODO: Train a logistic regression classifier on embeddings\n",
    "    # Use LogisticRegression(max_iter=1000, random_state=42)\n",
    "    \n",
    "    # TODO: Make predictions and calculate accuracies\n",
    "    # Use accuracy_score to calculate train_acc_embeddings and test_acc_embeddings\n",
    "        \n",
    "    # TODO: Return results in the specified format:\n",
    "    # return {\n",
    "    #     'train_acc': train_acc_embeddings, \n",
    "    #     'test_acc': test_acc_embeddings, \n",
    "    #     'predictions': test_pred_embeddings,\n",
    "    #     'embeddings_train': X_train_embeddings,\n",
    "    #     'embeddings_test': X_test_embeddings\n",
    "    # }\n",
    "    pass\n",
    "\n",
    "# Run OpenAI embeddings experiment\n",
    "openai_results = openai_embeddings_classification(train_texts, test_texts, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4eeaf",
   "metadata": {},
   "source": [
    "## Problem 3C: Compare Approaches\n",
    "\n",
    "**Your task**: Analyze the results from both approaches by:\n",
    "1. Running the comparison code below\n",
    "2. Examining the accuracy differences\n",
    "3. Understanding the trade-offs between sparse (BoW) vs dense (embeddings) representations\n",
    "4. Answering the reflection questions at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f9c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SENTIMENT ANALYSIS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "approaches = [\n",
    "    (\"Count Vectorizer (BoW)\", bow_results['count']),\n",
    "    (\"OpenAI Embeddings\", openai_results)\n",
    "]\n",
    "\n",
    "print(f\"{'Approach':<25} {'Train Acc':<10} {'Test Acc':<10} {'Overfitting':<12}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for name, results in approaches:\n",
    "    train_acc = results['train_acc']\n",
    "    test_acc = results['test_acc']\n",
    "    overfitting = train_acc - test_acc\n",
    "    print(f\"{name:<25} {train_acc:<10.3f} {test_acc:<10.3f} {overfitting:<12.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9cbcac",
   "metadata": {},
   "source": [
    "## Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification reports\n",
    "sentiment_names = ['negative', 'neutral', 'positive']\n",
    "\n",
    "print(\"\\n1. OpenAI Embeddings Results:\")\n",
    "print(classification_report(test_labels, openai_results['predictions'], \n",
    "                          target_names=sentiment_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd649f",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb237f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "methods = ['Count BoW', 'OpenAI']\n",
    "train_accs = [bow_results['count']['train_acc'], openai_results['train_acc']]\n",
    "test_accs = [bow_results['count']['test_acc'],  openai_results['test_acc']]\n",
    "\n",
    "axes[0].bar(methods, train_accs, alpha=0.7, label='Train Accuracy', color='blue')\n",
    "axes[0].bar(methods, test_accs, alpha=0.7, label='Test Accuracy', color='red')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Method Comparison')\n",
    "axes[0].legend()\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Confusion matrix for best method\n",
    "best_method = max(approaches, key=lambda x: x[1]['test_acc'])\n",
    "best_predictions = best_method[1]['predictions']\n",
    "\n",
    "cm = confusion_matrix(test_labels, best_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=sentiment_names, yticklabels=sentiment_names, ax=axes[1])\n",
    "axes[1].set_title(f'Confusion Matrix - {best_method[0]}')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "# Overfitting analysis\n",
    "overfitting_scores = [results['train_acc'] - results['test_acc'] for _, results in approaches]\n",
    "axes[2].bar(methods, overfitting_scores, color='green', alpha=0.7)\n",
    "axes[2].set_ylabel('Overfitting (Train - Test)')\n",
    "axes[2].set_title('Overfitting Comparison')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c94544",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7671f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find examples where methods disagree\n",
    "bow_pred = bow_results['count']['predictions']\n",
    "openai_pred = openai_results['predictions']\n",
    "\n",
    "# Find disagreements\n",
    "disagreements = np.where(bow_pred != openai_pred)[0]\n",
    "\n",
    "print(f\"\\n=== ERROR ANALYSIS ===\")\n",
    "print(f\"Methods disagree on {len(disagreements)}/{len(test_labels)} samples ({len(disagreements)/len(test_labels)*100:.1f}%)\")\n",
    "\n",
    "if len(disagreements) > 0:\n",
    "    print(f\"\\nSample disagreements:\")\n",
    "    for i in disagreements[:5]:  # Show first 5 disagreements\n",
    "        true_label = sentiment_names[test_labels[i]]\n",
    "        bow_label = sentiment_names[bow_pred[i]]\n",
    "        openai_label = sentiment_names[openai_pred[i]]\n",
    "        text = test_texts[i][:100] + \"...\" if len(test_texts[i]) > 100 else test_texts[i]\n",
    "        \n",
    "        print(f\"\\nText: {text}\")\n",
    "        print(f\"True: {true_label}, BoW: {bow_label}, OpenAI: {openai_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
